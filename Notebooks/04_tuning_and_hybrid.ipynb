{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb08531",
   "metadata": {},
   "source": [
    "### Notebook 04: Model Tuning and Hybrid Models\n",
    "\n",
    "This notebook tunes the baseline machine learning models (Logistic Regresssion, Random Forest, and XGBoost) and explores hybrid modeling approaches to improve prediction accuracy. Optuna is used for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca47929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16722dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>duplicateCount</th>\n",
       "      <th>elementCount</th>\n",
       "      <th>relationshipCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>num_formats</th>\n",
       "      <th>hasWarning</th>\n",
       "      <th>hasDuplicate</th>\n",
       "      <th>rel_elem_ratio</th>\n",
       "      <th>view_elem_ratio</th>\n",
       "      <th>source_GitHub</th>\n",
       "      <th>source_Other</th>\n",
       "      <th>source_Unknown</th>\n",
       "      <th>language_bs</th>\n",
       "      <th>language_ca</th>\n",
       "      <th>language_cs</th>\n",
       "      <th>language_da</th>\n",
       "      <th>language_de</th>\n",
       "      <th>language_en</th>\n",
       "      <th>language_es</th>\n",
       "      <th>language_fi</th>\n",
       "      <th>language_fr</th>\n",
       "      <th>language_hr</th>\n",
       "      <th>language_id</th>\n",
       "      <th>language_it</th>\n",
       "      <th>language_ko</th>\n",
       "      <th>language_ms</th>\n",
       "      <th>language_nb</th>\n",
       "      <th>language_nl</th>\n",
       "      <th>language_nn</th>\n",
       "      <th>language_pl</th>\n",
       "      <th>language_pt</th>\n",
       "      <th>language_ru</th>\n",
       "      <th>language_sl</th>\n",
       "      <th>language_sv</th>\n",
       "      <th>language_tl</th>\n",
       "      <th>language_vi</th>\n",
       "      <th>language_yo</th>\n",
       "      <th>language_zh</th>\n",
       "      <th>arb_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id-48fb3807bfa249a9bae607b6a92cc390</td>\n",
       "      <td>LAE</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>296</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.084507</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4cc127d7-6937-42e8-99fb-19f0f6f4991a</td>\n",
       "      <td>Baseline Media Production</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_7RWQ8CqVEey-A40W5C_9dw</td>\n",
       "      <td>buhService</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3846c562-eab4-4e07-aa95-87703e0e0e69</td>\n",
       "      <td>Data model test</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_ay028PGjEeqygJczXaaxEQ</td>\n",
       "      <td>payments-arch</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  ... arb_outcome\n",
       "0   id-48fb3807bfa249a9bae607b6a92cc390  ...           0\n",
       "1  4cc127d7-6937-42e8-99fb-19f0f6f4991a  ...           1\n",
       "2               _7RWQ8CqVEey-A40W5C_9dw  ...           0\n",
       "3  3846c562-eab4-4e07-aa95-87703e0e0e69  ...           1\n",
       "4               _ay028PGjEeqygJczXaaxEQ  ...           1\n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "preprocessed_file = r'C:\\Users\\anitr\\AAI590_Capstone\\AAI590_Capstone_AH\\Data\\ea_modelset\\eamodelset\\dataset\\preprocessed_models.csv'\n",
    "models_df = pd.read_csv(preprocessed_file)\n",
    "models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1870cef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models DataFrame shape: (978, 41)\n",
      "Features shape: (978, 38)\n",
      "Target shape: (978,)\n"
     ]
    }
   ],
   "source": [
    "# Define arb_outcome as target variable (y) and features (X)\n",
    "X = models_df.drop(columns=['name','id','arb_outcome'])\n",
    "y = models_df['arb_outcome']\n",
    "\n",
    "# Check shape of X and y\n",
    "print(f\"Models DataFrame shape: {models_df.shape}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c113e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (782, 38), (782,)\n",
      "Test set shape: (196, 38), (196,)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dde49b",
   "metadata": {},
   "source": [
    "### XGBOOST - HYPERPARAMETER TUNING WITH OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6832ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:51:51,612] A new study created in memory with name: no-name-acd4a802-87ef-4951-829d-53443ea8a024\n",
      "Best trial: 0. Best value: 0.981955:   4%|▍         | 1/25 [00:02<00:54,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:51:53,879] Trial 0 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 225, 'learning_rate': 0.10127098673703337, 'max_depth': 12, 'subsample': 0.945601409106067, 'colsample_bytree': 0.6965270370415978, 'gamma': 3.2108108771096373, 'min_child_weight': 3}. Best is trial 0 with value: 0.9819554682423414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981955:   8%|▊         | 2/25 [00:03<00:44,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:51:55,578] Trial 1 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 285, 'learning_rate': 0.21790987712319423, 'max_depth': 8, 'subsample': 0.9379372675096971, 'colsample_bytree': 0.8472522617357415, 'gamma': 2.2334149710812525, 'min_child_weight': 4}. Best is trial 0 with value: 0.9819554682423414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981955:  12%|█▏        | 3/25 [00:05<00:40,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:51:57,318] Trial 2 finished with value: 0.9807381413367016 and parameters: {'n_estimators': 371, 'learning_rate': 0.039280511496430366, 'max_depth': 4, 'subsample': 0.7340724347635605, 'colsample_bytree': 0.7613090801040259, 'gamma': 3.214681237941246, 'min_child_weight': 2}. Best is trial 0 with value: 0.9819554682423414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.983403:  16%|█▌        | 4/25 [00:07<00:37,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:51:59,068] Trial 3 finished with value: 0.983402884317829 and parameters: {'n_estimators': 446, 'learning_rate': 0.16117142847326213, 'max_depth': 12, 'subsample': 0.9736545849103231, 'colsample_bytree': 0.7867759783129827, 'gamma': 4.508548952978752, 'min_child_weight': 2}. Best is trial 3 with value: 0.983402884317829.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.98651:  20%|██        | 5/25 [00:09<00:35,  1.80s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:00,841] Trial 4 finished with value: 0.9865104372579466 and parameters: {'n_estimators': 397, 'learning_rate': 0.017486265463762897, 'max_depth': 11, 'subsample': 0.7894606592238029, 'colsample_bytree': 0.76007169833078, 'gamma': 0.42768935321655543, 'min_child_weight': 2}. Best is trial 4 with value: 0.9865104372579466.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.98651:  28%|██▊       | 7/25 [00:10<00:21,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:02,423] Trial 5 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 373, 'learning_rate': 0.03352081992157196, 'max_depth': 4, 'subsample': 0.8125453177197373, 'colsample_bytree': 0.6237924293976073, 'gamma': 2.469005074505817, 'min_child_weight': 4}. Best is trial 4 with value: 0.9865104372579466.\n",
      "[I 2025-12-07 13:52:02,574] Trial 6 finished with value: 0.9807381413367016 and parameters: {'n_estimators': 380, 'learning_rate': 0.02048384915867571, 'max_depth': 10, 'subsample': 0.7631610260529992, 'colsample_bytree': 0.8635005755026626, 'gamma': 4.075573419798709, 'min_child_weight': 6}. Best is trial 4 with value: 0.9865104372579466.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.98651:  36%|███▌      | 9/25 [00:11<00:10,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:02,724] Trial 7 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 425, 'learning_rate': 0.058970245535082934, 'max_depth': 6, 'subsample': 0.9824376116951496, 'colsample_bytree': 0.6683450004989513, 'gamma': 1.0549991284577243, 'min_child_weight': 6}. Best is trial 4 with value: 0.9865104372579466.\n",
      "[I 2025-12-07 13:52:02,866] Trial 8 finished with value: 0.9457508345546621 and parameters: {'n_estimators': 298, 'learning_rate': 0.013061889539566001, 'max_depth': 6, 'subsample': 0.7138312155885433, 'colsample_bytree': 0.9792276322125337, 'gamma': 4.433402432710433, 'min_child_weight': 8}. Best is trial 4 with value: 0.9865104372579466.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.98651:  40%|████      | 10/25 [00:11<00:07,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:02,976] Trial 9 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 278, 'learning_rate': 0.055990288019580135, 'max_depth': 12, 'subsample': 0.8840154608609796, 'colsample_bytree': 0.9997615762488948, 'gamma': 4.76798357502854, 'min_child_weight': 3}. Best is trial 4 with value: 0.9865104372579466.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  48%|████▊     | 12/25 [00:11<00:04,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:03,206] Trial 10 finished with value: 0.9118516479183268 and parameters: {'n_estimators': 469, 'learning_rate': 0.01156846324385182, 'max_depth': 9, 'subsample': 0.607921462724954, 'colsample_bytree': 0.9018201914680373, 'gamma': 0.43025053752562226, 'min_child_weight': 10}. Best is trial 4 with value: 0.9865104372579466.\n",
      "[I 2025-12-07 13:52:03,375] Trial 11 finished with value: 0.989158277185438 and parameters: {'n_estimators': 492, 'learning_rate': 0.2516756545286703, 'max_depth': 11, 'subsample': 0.8477864785313033, 'colsample_bytree': 0.7655106019974527, 'gamma': 1.276914562872955, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  56%|█████▌    | 14/25 [00:12<00:02,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:03,542] Trial 12 finished with value: 0.989158277185438 and parameters: {'n_estimators': 496, 'learning_rate': 0.10455010293133245, 'max_depth': 10, 'subsample': 0.8507545454363709, 'colsample_bytree': 0.7355371950772454, 'gamma': 1.3215315564367387, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:03,709] Trial 13 finished with value: 0.989158277185438 and parameters: {'n_estimators': 500, 'learning_rate': 0.28084677233621547, 'max_depth': 10, 'subsample': 0.8603413591071123, 'colsample_bytree': 0.7173302255101637, 'gamma': 1.5365119358855117, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  60%|██████    | 15/25 [00:12<00:02,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:03,885] Trial 14 finished with value: 0.989158277185438 and parameters: {'n_estimators': 497, 'learning_rate': 0.11983599854823543, 'max_depth': 9, 'subsample': 0.857300109761848, 'colsample_bytree': 0.826345139282052, 'gamma': 1.4862425387746545, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  68%|██████▊   | 17/25 [00:12<00:01,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:04,072] Trial 15 finished with value: 0.9707991489976324 and parameters: {'n_estimators': 432, 'learning_rate': 0.09431381356552218, 'max_depth': 7, 'subsample': 0.6773432497247874, 'colsample_bytree': 0.6033874299989179, 'gamma': 0.009737929987523986, 'min_child_weight': 4}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:04,186] Trial 16 finished with value: 0.9777869388435164 and parameters: {'n_estimators': 324, 'learning_rate': 0.17476057876038778, 'max_depth': 10, 'subsample': 0.9032022975065774, 'colsample_bytree': 0.7374295506104322, 'gamma': 1.8007441036060574, 'min_child_weight': 8}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  76%|███████▌  | 19/25 [00:12<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:04,353] Trial 17 finished with value: 0.989158277185438 and parameters: {'n_estimators': 467, 'learning_rate': 0.07441744161500245, 'max_depth': 11, 'subsample': 0.8259129115324532, 'colsample_bytree': 0.6756064323262831, 'gamma': 0.9368858770654205, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:04,488] Trial 18 finished with value: 0.9819554682423414 and parameters: {'n_estimators': 413, 'learning_rate': 0.28020389891051783, 'max_depth': 8, 'subsample': 0.9031815673654919, 'colsample_bytree': 0.8005252627121945, 'gamma': 3.0066669833256374, 'min_child_weight': 5}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  84%|████████▍ | 21/25 [00:13<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:04,645] Trial 19 finished with value: 0.9833862309464174 and parameters: {'n_estimators': 466, 'learning_rate': 0.14017890573961136, 'max_depth': 11, 'subsample': 0.8361829959634607, 'colsample_bytree': 0.6316418248059289, 'gamma': 1.9690633585746635, 'min_child_weight': 3}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:04,760] Trial 20 finished with value: 0.9719437643767158 and parameters: {'n_estimators': 339, 'learning_rate': 0.20635592111862402, 'max_depth': 9, 'subsample': 0.7787321154715885, 'colsample_bytree': 0.8882443783062456, 'gamma': 1.019350105766834, 'min_child_weight': 7}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158:  92%|█████████▏| 23/25 [00:13<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:04,929] Trial 21 finished with value: 0.989158277185438 and parameters: {'n_estimators': 500, 'learning_rate': 0.2714450558896942, 'max_depth': 10, 'subsample': 0.8611719550978623, 'colsample_bytree': 0.7318947256396325, 'gamma': 0.9400172879496328, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:05,095] Trial 22 finished with value: 0.989158277185438 and parameters: {'n_estimators': 500, 'learning_rate': 0.28107936341763085, 'max_depth': 10, 'subsample': 0.8689609803690862, 'colsample_bytree': 0.7248089781768803, 'gamma': 1.4774384882764053, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.989158: 100%|██████████| 25/25 [00:13<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-07 13:52:05,252] Trial 23 finished with value: 0.9877591954470054 and parameters: {'n_estimators': 454, 'learning_rate': 0.2002842010673283, 'max_depth': 11, 'subsample': 0.9278722478845978, 'colsample_bytree': 0.6965277360632465, 'gamma': 1.5331551680748203, 'min_child_weight': 2}. Best is trial 11 with value: 0.989158277185438.\n",
      "[I 2025-12-07 13:52:05,419] Trial 24 finished with value: 0.9863131381222979 and parameters: {'n_estimators': 485, 'learning_rate': 0.12958566035006258, 'max_depth': 9, 'subsample': 0.8222609133340955, 'colsample_bytree': 0.7914706632469731, 'gamma': 2.6885968499815083, 'min_child_weight': 1}. Best is trial 11 with value: 0.989158277185438.\n",
      "Best hyperparameters:  {'n_estimators': 492, 'learning_rate': 0.2516756545286703, 'max_depth': 11, 'subsample': 0.8477864785313033, 'colsample_bytree': 0.7655106019974527, 'gamma': 1.276914562872955, 'min_child_weight': 1}\n",
      "Best F1 Macro Score:  0.989158277185438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use optuna to optimize hyperparameters for XGBoost\n",
    "def xgb_objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    xgb = XGBClassifier(**param)\n",
    "    score = cross_val_score(xgb, X_train, y_train, cv=3, scoring='f1_macro', n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_objective, n_trials=25, show_progress_bar=True)\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best F1 Macro Score: \", study.best_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02144a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Model Accuracy: 0.9949\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        50\n",
      "           1       1.00      0.99      1.00       105\n",
      "           2       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           0.99       196\n",
      "   macro avg       0.99      1.00      1.00       196\n",
      "weighted avg       0.99      0.99      0.99       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train  optimized XGBoost model\n",
    "xgboost_tuned = XGBClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=study.best_params['n_estimators'], \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    max_depth=study.best_params['max_depth'], \n",
    "    subsample=study.best_params['subsample'], \n",
    "    colsample_bytree=study.best_params['colsample_bytree'], \n",
    "    gamma=study.best_params['gamma'],\n",
    "    min_child_weight=study.best_params['min_child_weight'],\n",
    "    objective=\"multi:softprob\", \n",
    "    num_class=3\n",
    ")\n",
    "xgboost_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = xgboost_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate tuned XGBoost model\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"Tuned XGBoost Model Accuracy: {accuracy_tuned:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46c6c7",
   "metadata": {},
   "source": [
    "### RANDOM FOREST - HYPERPARAMETER TUNING WITH OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47d00ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:22,500] A new study created in memory with name: no-name-6622ec08-e92a-487d-a943-95820816e44d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.927799:   4%|▍         | 1/25 [00:03<01:28,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:26,209] Trial 0 finished with value: 0.9277994701601587 and parameters: {'n_estimators': 418, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.9277994701601587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.954474:   8%|▊         | 2/25 [00:05<01:01,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:28,200] Trial 1 finished with value: 0.9544739068815103 and parameters: {'n_estimators': 332, 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 1 with value: 0.9544739068815103.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.988955:  12%|█▏        | 3/25 [00:08<00:56,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:30,618] Trial 2 finished with value: 0.9889546306063924 and parameters: {'n_estimators': 407, 'max_depth': 33, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.9889546306063924.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.988955:  16%|█▌        | 4/25 [00:10<00:49,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:32,688] Trial 3 finished with value: 0.9835959647655149 and parameters: {'n_estimators': 324, 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.9889546306063924.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.988955:  20%|██        | 5/25 [00:12<00:44,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:34,639] Trial 4 finished with value: 0.943202946718133 and parameters: {'n_estimators': 239, 'max_depth': 36, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 2 with value: 0.9889546306063924.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.991437:  24%|██▍       | 6/25 [00:14<00:42,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:36,822] Trial 5 finished with value: 0.9914374928014849 and parameters: {'n_estimators': 425, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.9914374928014849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.991437:  28%|██▊       | 7/25 [00:14<00:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:37,357] Trial 6 finished with value: 0.9726047938343018 and parameters: {'n_estimators': 464, 'max_depth': 37, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced_subsample'}. Best is trial 5 with value: 0.9914374928014849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.991437:  32%|███▏      | 8/25 [00:15<00:20,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:37,674] Trial 7 finished with value: 0.954864852521985 and parameters: {'n_estimators': 239, 'max_depth': 34, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 5 with value: 0.9914374928014849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.991437:  36%|███▌      | 9/25 [00:15<00:16,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:38,291] Trial 8 finished with value: 0.9644445405359311 and parameters: {'n_estimators': 308, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced_subsample'}. Best is trial 5 with value: 0.9914374928014849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.991437:  40%|████      | 10/25 [00:16<00:12,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:38,670] Trial 9 finished with value: 0.9591941812571996 and parameters: {'n_estimators': 310, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 5 with value: 0.9914374928014849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  44%|████▍     | 11/25 [00:16<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:39,424] Trial 10 finished with value: 0.9926668537044878 and parameters: {'n_estimators': 575, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  48%|████▊     | 12/25 [00:17<00:10,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:40,225] Trial 11 finished with value: 0.9926668537044878 and parameters: {'n_estimators': 584, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  52%|█████▏    | 13/25 [00:18<00:09,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:41,060] Trial 12 finished with value: 0.99035905837628 and parameters: {'n_estimators': 595, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  56%|█████▌    | 14/25 [00:19<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:41,871] Trial 13 finished with value: 0.99035905837628 and parameters: {'n_estimators': 599, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  60%|██████    | 15/25 [00:20<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:42,565] Trial 14 finished with value: 0.991583073247828 and parameters: {'n_estimators': 517, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  64%|██████▍   | 16/25 [00:20<00:06,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:43,188] Trial 15 finished with value: 0.9861710529297048 and parameters: {'n_estimators': 528, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  68%|██████▊   | 17/25 [00:21<00:05,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:43,844] Trial 16 finished with value: 0.9612623951402955 and parameters: {'n_estimators': 540, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  72%|███████▏  | 18/25 [00:21<00:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:44,400] Trial 17 finished with value: 0.9860439726888518 and parameters: {'n_estimators': 488, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  76%|███████▌  | 19/25 [00:22<00:03,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:45,041] Trial 18 finished with value: 0.9847839365904066 and parameters: {'n_estimators': 553, 'max_depth': 16, 'min_samples_split': 20, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  80%|████████  | 20/25 [00:23<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:45,589] Trial 19 finished with value: 0.9861710529297048 and parameters: {'n_estimators': 469, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced_subsample'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  84%|████████▍ | 21/25 [00:23<00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:46,181] Trial 20 finished with value: 0.9786990472735696 and parameters: {'n_estimators': 577, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  88%|████████▊ | 22/25 [00:24<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:46,781] Trial 21 finished with value: 0.991583073247828 and parameters: {'n_estimators': 501, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  92%|█████████▏| 23/25 [00:24<00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:47,435] Trial 22 finished with value: 0.9926668537044878 and parameters: {'n_estimators': 556, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667:  96%|█████████▌| 24/25 [00:25<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:48,131] Trial 23 finished with value: 0.9926668537044878 and parameters: {'n_estimators': 561, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.992667: 100%|██████████| 25/25 [00:26<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 01:02:48,810] Trial 24 finished with value: 0.9926668537044878 and parameters: {'n_estimators': 561, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.9926668537044878.\n",
      "Best hyperparameters for Random Forest:  {'n_estimators': 575, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Best F1 Macro Score for Random Forest:  0.9926668537044878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use optuna to optimize hyperparameters for Random Forest\n",
    "def rf_objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 40),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced', 'balanced_subsample']),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(**param)\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1_macro', n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(rf_objective, n_trials=25, show_progress_bar=True)\n",
    "print(\"Best hyperparameters for Random Forest: \", study_rf.best_params)\n",
    "print(\"Best F1 Macro Score for Random Forest: \", study_rf.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d58a2274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Model Accuracy: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00       105\n",
      "           2       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00       196\n",
      "   macro avg       1.00      1.00      1.00       196\n",
      "weighted avg       1.00      1.00      1.00       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train optimized Random Forest model\n",
    "rf_tuned = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=study_rf.best_params['n_estimators'],\n",
    "    max_depth=study_rf.best_params['max_depth'],\n",
    "    min_samples_split=study_rf.best_params['min_samples_split'],\n",
    "    min_samples_leaf=study_rf.best_params['min_samples_leaf'],\n",
    "    max_features=study_rf.best_params['max_features'],\n",
    "    bootstrap=study_rf.best_params['bootstrap'],\n",
    "    class_weight=study_rf.best_params['class_weight']\n",
    ")\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred_rf_tuned = rf_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate tuned Random Forest model\n",
    "accuracy_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)\n",
    "print(f\"Tuned Random Forest Model Accuracy: {accuracy_rf_tuned:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef836a2c",
   "metadata": {},
   "source": [
    "#### After hyperparameter tuning, the XGBoost model achieved an accuracy of 0.995, while the Random Forest model achieved an accuracy of 1.0 on the test set. The XGBoost model showed strong performance with a high F1 score across all classes, indicating its effectiveness in predicting ARB outcomes, but no improvement. The Random Forest modeled performed perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28a097",
   "metadata": {},
   "source": [
    "#### Next, ensemble models were created using both soft voting and stacking classifiers to combine the strengths of individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c8d75",
   "metadata": {},
   "source": [
    "### HYBRID MODEL - SOFT VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2541450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model Soft Voting Accuracy: 0.9949\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        50\n",
      "           1       1.00      0.99      1.00       105\n",
      "           2       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           0.99       196\n",
      "   macro avg       0.99      1.00      1.00       196\n",
      "weighted avg       0.99      0.99      0.99       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a soft voting classifier as hybrid model\n",
    "hybrid_model_softvoting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgboost', xgboost_tuned),\n",
    "        ('random_forest', rf_tuned),\n",
    "        ('logistic_regression', LogisticRegression(max_iter=2000))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "#Train ensemble\n",
    "hybrid_model_softvoting.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate hybrid model\n",
    "y_pred_hybrid = hybrid_model_softvoting.predict(X_test)\n",
    "accuracy_hybrid = accuracy_score(y_test, y_pred_hybrid)\n",
    "print(f\"Hybrid Model Soft Voting Accuracy: {accuracy_hybrid:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_hybrid))\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186025eb",
   "metadata": {},
   "source": [
    "### HYBRID MODEL - STACKING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f164d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model Stacking Accuracy: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00       105\n",
      "           2       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00       196\n",
      "   macro avg       1.00      1.00      1.00       196\n",
      "weighted avg       1.00      1.00      1.00       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a stacking classifier as hybrid model\n",
    "hybrid_model_stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgboost', xgboost_tuned),\n",
    "        ('random_forest', rf_tuned),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train ensemble\n",
    "hybrid_model_stacking.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate hybrid model\n",
    "y_pred_hybrid_stack = hybrid_model_stacking.predict(X_test)\n",
    "accuracy_hybrid_stack = accuracy_score(y_test, y_pred_hybrid_stack)\n",
    "print(f\"Hybrid Model Stacking Accuracy: {accuracy_hybrid_stack:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_hybrid_stack))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6df83",
   "metadata": {},
   "source": [
    "#### The stacking classifier achieved an accuracy of 1.00 on the test set, similar to the tuned Random Forest model. The soft voting classifier achived an accuract of 0.995, similar to the tuned XGBoost model, however, it did not outperform the Random Forest model or stacking classifier, which achieved perfect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bb1ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0        XGBoost Tuned  0.994898\n",
      "1  Random Forest Tuned  1.000000\n",
      "2   Hybrid Soft Voting  0.994898\n",
      "3      Hybrid Stacking  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table of model accuracies\n",
    "performance_data = {\n",
    "    'Model': ['XGBoost Tuned', 'Random Forest Tuned', 'Hybrid Soft Voting', 'Hybrid Stacking'],\n",
    "    'Accuracy': [accuracy_tuned, accuracy_rf_tuned, accuracy_hybrid, accuracy_hybrid_stack]\n",
    "}\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(performance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c344b0a",
   "metadata": {},
   "source": [
    "#### Although the hybrid stacking and random forest models both achieved perfect accuracy, the stacking classifier provides a more robust approach by leveraging multiple models. Random Forest, however, produces more stable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787d1514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned and hybrid models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save tuned and hybrid models\n",
    "model_dir = r'C:\\Users\\anitr\\AAI590_Capstone\\AAI590_Capstone_AH\\Models\\tuned_and_hybrid_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "joblib.dump(xgboost_tuned, os.path.join(model_dir, 'xgboost_tuned.pkl'))\n",
    "joblib.dump(rf_tuned, os.path.join(model_dir, 'rf_tuned.pkl'))\n",
    "joblib.dump(hybrid_model_softvoting, os.path.join(model_dir, 'hybrid_softvoting.pkl'))\n",
    "joblib.dump(hybrid_model_stacking, os.path.join(model_dir, 'hybrid_stacking.pkl'))\n",
    "\n",
    "print(\"Tuned and hybrid models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aai_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
